<html >
<head >
<title >
Existence of Singular Value Decomposition
</title>
<meta ></meta>
<meta ></meta>
<meta ></meta>
<meta ></meta>
<meta ></meta>
</head>
<body  bgcolor="#CFFFCC" lang="EN">
<p >
<!--Converted with LaTeX2HTML 96.1-h (September 30, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
</p>
<link ></link>
<a  name="tex2html203"></a>
<a  name="tex2html203"></a>
<a  name="tex2html203"></a>
<a  href="node13.html" name="tex2html203">
<img ></img>
</a>
<font  size="+1">
<a  name="tex2html201"></a>
<a  name="tex2html201"></a>
<a  name="tex2html201"></a>
<a  href="node11.html" name="tex2html201">
<img ></img>
</a>
<a  name="tex2html195"></a>
<a  name="tex2html195"></a>
<a  name="tex2html195"></a>
<a  href="node11.html" name="tex2html195">
<img ></img>
</a>
</font>
<br ></br>
<hr ></hr>
<h1 >
<a  name="SECTION00013100000000000000"></a>
Existence of Singular Value Decomposition
</h1>
<p ></p>
<hr ></hr>
<p >
<a  name="Proposition-3-1-1"></a>
<font  size="+1">
<b >
Proposition 3.1.1.
</b>
If
<img ></img>
<img ></img>
<b ></b>
has
<a  href="../lin1/node10.html#orthogonal_vector_system">
orthonormal
</a>
columns, then there exists
<img ></img>
such that
<img ></img>
is
<a  href="../lin1/node10.html#orthogonal_vector_system">
orthogonal,
</a>
where the
<a  href="../lin1/node10.html#orthogonalcompl">
orthogonal complement
</a>
<img ></img>
of the span of column vectors of the matrix
<i >
V
</i>
<sub >
1
</sub>
is equal to the span
<img ></img>
of the column vectors of the matrix
<i >
V
</i>
<sub >
2
</sub>
, i.e.,
<img ></img>
</font>
</p>
<p >
<font  size="+1">
<i >
Proof
</i>
is basing on the
<a  href="../lin1/node10.html#Gram-Schmidt">
Gram-Schmidt orthogonalization
</a>
.
</font>
</p>
<p >
<font  size="+1">
<b >
Proposition 3.1.2.
</b>
If
<img ></img>
and
<img ></img>
has orthonormal columns, then
<img ></img>
</font>
</p>
<p >
<font  size="+1">
<i >
Proof.
</i>
If
<img ></img>
has
<a  href="../lin1/node10.html#orthogonal_vector_system">
orthonormal columns
</a>
, then
<img ></img>
and
</font>
<br ></br>
<img ></img>
<br ></br>
</p>
<p >
<a  name="Proposition3.1.3."></a>
<font  size="+1">
<b >
Proposition 3.1.3.
</b>
Let
<img ></img>
If
<img ></img>
and
<img ></img>
are
<a  href="../lin1/node10.html#orthogonal_vector_system">
orthogonal
</a>
, then
<br ></br>
<img ></img>
<br ></br>
and
<br ></br>
<a  name="1"></a>
</font>
<img ></img>
<br ></br>
</p>
<p >
<font  size="+1">
<i >
Prove
</i>
relation
<a  href="#1">
(1)
</a>
:
</font>
<br ></br>
<img ></img>
<br ></br>
<br ></br>
<img ></img>
<br ></br>
</p>
<p >
<a  name="Proposition3.1.4"></a>
<font  size="+1">
<b >
Proposition 3.1.4
</b>
<i >
(existence theorem of the singular value decomposition).
</i>
If
<img ></img>
then there exist orthogonal matrices
<br ></br>
<img ></img>
<br ></br>
and
<br ></br>
<img ></img>
<br ></br>
such that
<br ></br>
<a  name="2"></a>
<img ></img>
<br ></br>
with
</font>
<br ></br>
<img ></img>
<br ></br>
</p>
<p >
<font  size="+1">
<i >
Proof.
</i>
By the definition of the matrix 2-norm there exist the vectors
<img ></img>
and
<img ></img>
such that
<img ></img>
where
<img ></img>
and
<img ></img>
<a  href="#Proposition-3-1-1">
By Proposition 3.1.1
</a>
, there exist the matrices
<img ></img>
and
<img ></img>
such that
<img ></img>
<img ></img>
and
<img ></img>
are
<a  href="../lin1/node10.html#orthogonal_vector_system">
orthogonal.
</a>
Using this notation, we obtain that
<br ></br>
<img ></img>
<br ></br>
<br ></br>
<img ></img>
<br ></br>
<br ></br>
<img ></img>
<br ></br>
with
<img ></img>
and
<i >
B
</i>
=
<i >
U
</i>
<sub >
2
</sub>
<i >
<sup >
T
</sup>
AV
</i>
<sub >
2
</sub>
. Since
<br ></br>
<img ></img>
<br ></br>
then
<br ></br>
<img ></img>
<br ></br>
On the other hand,
<br ></br>
<img ></img>
<br ></br>
and therefore,
<br ></br>
<img ></img>
<br ></br>
By Proposition 3.1.3, we find that
<img ></img>
Consequently,
<img ></img>
0 and
<img ></img>
We obtain that
<br ></br>
<img ></img>
<br ></br>
or
<br ></br>
<img ></img>
<br ></br>
and
<br ></br>
<img ></img>
<br ></br>
Thus, the matrices
<i >
A
<sup >
T
</sup>
A
</i>
and
<img ></img>
are similar, and they have the same eigenvalues. Consequently,
<br ></br>
<img ></img>
<br ></br>
where
<img ></img>
as
<img ></img>
is the greatest eigenvalue of
<i >
A
<sup >
T
</sup>
A
</i>
. Note that since
<i >
A
<sup >
T
</sup>
A
</i>
is symmetric then all eigenvalues of
<i >
A
<sup >
T
</sup>
A
</i>
are non-negative. Reasoning used for the matrix
<i >
A
</i>
we shall use in the next step for the matrix
<i >
B
</i>
etc. So, on the main diagonal of
<img ></img>
there are the square roots of the eigenvalues of
<i >
A
<sup >
T
</sup>
A
</i>
, more exactly, the first
<img ></img>
of them in descending order.
</font>
</p>
<p >
<a  name="singularvaluedecomp"></a>
<a  name="singularvalues"></a>
<font  size="+1">
<b >
Definition 3.1.1.
</b>
The relation in form (2) is called the
<i >
singular value decomposition
</i>
of the matrix
<img ></img>
The elements
<img ></img>
<i >
<img ></img>
</i>
=
<img ></img>
on the main diagonal of
<img ></img>
are called the
<i >
singular values
</i>
of the matrix
<i >
A.
</i>
</font>
</p>
<p ></p>
<hr ></hr>
<a  href="node13.html" name="tex2html203">
<img ></img>
</a>
<font  size="+1">
<a  name="tex2html201"></a>
<a  name="tex2html201"></a>
<a  name="tex2html201"></a>
<a  href="node11.html" name="tex2html201">
<img ></img>
</a>
<a  name="tex2html195"></a>
<a  name="tex2html195"></a>
<a  name="tex2html195"></a>
<a  href="node11.html" name="tex2html195">
<img ></img>
</a>
</font>
<br ></br>
<p >
<!---- &amp;amp;lt;ADDRESS&amp;amp;gt;
&amp;amp;lt;I&amp;amp;gt;Toomas Lepikult &amp;amp;lt;BR&amp;amp;gt;
Wed Oct  8 08:53:27 EET DST 1997&amp;amp;lt;/I&amp;amp;gt;
&amp;amp;lt;/ADDRESS&amp;amp;gt;------>
</p>
</body>
</html>
